{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "loaded_model = joblib.load('svm.joblib')\n",
    "route800 = pd.read_csv('route_800.csv')\n",
    "route800 = route800.replace({'Nighttime': 0, 'Morning Peak': 1, 'Midday': 2, 'Evening Peak': 3})\n",
    "xTest800 = route800.loc[37695:, ['route_id', 'speed', 'occupancy_status', 'dist_to_stop', 'sched_speed', 'dwell_time', 'weekday', 'time_of_day', 'prevAvg']].values\n",
    "yPred800 = loaded_model.predict(xTest800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.75550157,  3.4487453 , 31.09728069, ..., 34.02851742,\n",
       "       34.02851742, 34.35395344])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "class feature_data_util():\n",
    "\n",
    "    def getAllData(self,filepath=None):\n",
    "        if filepath is None:\n",
    "            filepath = \"/content/sample_data/vp_clean_k_prev_busses.csv\"\n",
    "        df = pd.read_csv(filepath,low_memory=True)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        feature_columns = ['route_id','speed','occupancy_status','stop_name','dist_to_stop','sched_speed','dwell_time','weekday','time_of_day','prevAvg']\n",
    "        stop_names = list(df['stop_name'].unique())\n",
    "        stop_name_map = {stop_names[i]:i for i in range(len(stop_names))}\n",
    "        df['stop_name'] = df['stop_name'].map(stop_name_map)\n",
    "\n",
    "        time_of_days = list(df['time_of_day'].unique())\n",
    "        time_of_day_map = {time_of_days[i]:i for i in range(len(time_of_days))}\n",
    "        df['time_of_day'] = df['time_of_day'].map(time_of_day_map)\n",
    "\n",
    "\n",
    "        route_ids = list(df['route_id'].unique())\n",
    "        route_ids_map = {route_ids[i]:i for i in range(len(route_ids))}\n",
    "        df['route_id'] = df['route_id'].map(route_ids_map)\n",
    "\n",
    "        #X = df[feature_columns][:k]\n",
    "        X = df[feature_columns]\n",
    "\n",
    "        def convert1(x):\n",
    "            if x == 0:\n",
    "                return 0\n",
    "            return math.ceil(x / 60)\n",
    "\n",
    "        df['delay'] = df['delay'].apply(convert1)\n",
    "\n",
    "        def convert2(x):\n",
    "            if x <= 10:\n",
    "                return x\n",
    "            if 10 < x <= 15:\n",
    "                return 11\n",
    "            if 15 < x <= 20:\n",
    "                return 12\n",
    "            if 20 < x <= 30:\n",
    "                return 13\n",
    "            return 14\n",
    "\n",
    "        df['delay'] = df['delay'].apply(convert2)\n",
    "        y = df['delay'].values\n",
    "\n",
    "        #y = df['delay'][:k].values\n",
    "\n",
    "        #one_hot_y = np.eye(num_classes)[y]\n",
    "        return y,self.pre_process(X)\n",
    "\n",
    "\n",
    "    def pre_process(self,data):\n",
    "        mm = MinMaxScaler()\n",
    "        scaled_data = mm.fit_transform(data)\n",
    "        return scaled_data\n",
    "\n",
    "\n",
    "\n",
    "class FeatureDataSet(Dataset):\n",
    "    def __init__(self ,path=None):\n",
    "        dataUtil=feature_data_util()\n",
    "\n",
    "        self.lableData, self.trainData = dataUtil.getAllData(path)\n",
    "\n",
    "        self.trainData = torch.from_numpy(self.trainData.astype(np.float32))\n",
    "        self.lableData = torch.from_numpy(self.lableData.astype(np.float32))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        train  = self.trainData[index]\n",
    "        label  = self.lableData[index]\n",
    "\n",
    "        return train, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trainData)\n",
    "\n",
    "    def dataSet(self):\n",
    "        return self.trainData,self.lableData\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.fc_layers.extend([nn.Linear(10, 50), nn.ReLU()])\n",
    "        self.fc_layers.extend([nn.Linear(50, 200), nn.ReLU()])\n",
    "        self.fc_layers.extend([nn.Linear(200, 80),nn.ReLU()])\n",
    "        self.fc_layers.extend([nn.Linear(80, 30),nn.ReLU()])\n",
    "        self.fc_layers.extend([nn.Linear(30, 15)])\n",
    "\n",
    "        self.encoder = nn.Sequential(*self.fc_layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.encoder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "# Please change the path\n",
    "train_dataSet = FeatureDataSet(\"/content/sample_data/route_800.csv\")\n",
    "train_size = int(0.8 * len(train_dataSet))\n",
    "test_size = len(train_dataSet) - train_size\n",
    "train_dataSet, val_db = torch.utils.data.random_split(train_dataSet, [train_size, test_size],generator=torch.Generator().manual_seed(42))\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('/content/mode/model2.pth'))\n",
    "model.eval()\n",
    "pred = model.forward(val_db.dataset.trainData)\n",
    "\n",
    "pred = pred.argmax(dim=1)\n",
    "\n",
    "\n",
    "pred =pred.numpy().reshape(-1,1)\n",
    "df = pd.DataFrame(pred)\n",
    "df.columns = ['pred']\n",
    "delay_df = df.groupby(by=['pred'])['pred'].count()\n",
    "daley = {'delay':delay_df.index,'numbers':delay_df.values}\n",
    "daley_dis = pd.DataFrame(daley)\n",
    "plt.figure(figsize=(15,10))\n",
    "seaborn.barplot(daley_dis['delay'],daley_dis['numbers'],color = 'salmon')\n",
    "plt.xlabel(\"delay time \")\n",
    "plt.ylabel(\"number \")\n",
    "plt.title(\"route 800 distrubution of Residuals\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
